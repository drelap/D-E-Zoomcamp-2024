{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa32a362-7b23-443b-a01c-22932f11cbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7fabf2-0e20-40da-99c4-062cda685c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"homework05\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a943cca-37c4-40e2-83d9-0730152b06ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1: What is the spark version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "787ac740-0085-4c9b-848c-95ce2cc83c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362c6f6-1256-43ce-8fce-59fb6c2db902",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf92e4a-3423-41e8-a964-4322cba4a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-06 17:10:28--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T171028Z&X-Amz-Expires=300&X-Amz-Signature=584168f9457ac2bcac0a0bc4cdc5ab5b5ecd53569779670f3687d1b3e1512d63&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-06 17:10:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T171028Z&X-Amz-Expires=300&X-Amz-Signature=584168f9457ac2bcac0a0bc4cdc5ab5b5ecd53569779670f3687d1b3e1512d63&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M   111MB/s    in 0.2s    \n",
      "\n",
      "2024-03-06 17:10:30 (111 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "\n",
    "! wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d294f83a-1a0a-4fa5-ad06-70506615d95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unzip file\n",
    "!gunzip fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36722ee5-df78-4612-8b0f-276cf4c8b281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897494 fhv_tripdata_2019-10.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c4ae2f-9449-48fa-bd49-402594b886cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8c269f-68e0-4ab5-af87-0ed8c4c5cee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00009', pickup_datetime='2019-10-01 00:23:00', dropOff_datetime='2019-10-01 00:35:00', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00013', pickup_datetime='2019-10-01 00:11:29', dropOff_datetime='2019-10-01 00:13:22', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00013'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:11:43', dropOff_datetime='2019-10-01 00:37:20', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:56:29', dropOff_datetime='2019-10-01 00:57:47', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:23:09', dropOff_datetime='2019-10-01 00:28:27', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21bc3aa9-53d5-4afe-a9aa-8441a9aa9952",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfeeb309-f13b-4d6d-a48f-e611a042ca3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data with define schema\n",
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PULocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .schema(schema)\\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b8888af-79cd-4008-963c-10bee9e46cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00009', pickup_datetime=datetime.datetime(2019, 10, 1, 0, 23), dropoff_datetime=datetime.datetime(2019, 10, 1, 0, 35), PULocationID=264, DOLocationID=264, SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00013', pickup_datetime=datetime.datetime(2019, 10, 1, 0, 11, 29), dropoff_datetime=datetime.datetime(2019, 10, 1, 0, 13, 22), PULocationID=264, DOLocationID=264, SR_Flag=None, Affiliated_base_number='B00013'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime=datetime.datetime(2019, 10, 1, 0, 11, 43), dropoff_datetime=datetime.datetime(2019, 10, 1, 0, 37, 20), PULocationID=264, DOLocationID=264, SR_Flag=None, Affiliated_base_number='B00014'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime=datetime.datetime(2019, 10, 1, 0, 56, 29), dropoff_datetime=datetime.datetime(2019, 10, 1, 0, 57, 47), PULocationID=264, DOLocationID=264, SR_Flag=None, Affiliated_base_number='B00014'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime=datetime.datetime(2019, 10, 1, 0, 23, 9), dropoff_datetime=datetime.datetime(2019, 10, 1, 0, 28, 27), PULocationID=264, DOLocationID=264, SR_Flag=None, Affiliated_base_number='B00014')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7409d8e-7dbb-4a56-b970-4ac80e8085c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# repartition the df into 6 partitions as requested\n",
    "df = df.repartition(numPartitions=6)\n",
    "\n",
    "df.write.parquet('data/homework5/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "925d6225-7cee-462a-b698-45193c9c2b01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 37640\n",
      "-rw-r--r-- 1 andre andre       0 Mar  6 17:24 _SUCCESS\n",
      "-rw-r--r-- 1 andre andre 6424988 Mar  6 17:24 part-00000-9fcac57f-9abd-4582-bce9-76f302afde09-c000.snappy.parquet\n",
      "-rw-r--r-- 1 andre andre 6417333 Mar  6 17:24 part-00001-9fcac57f-9abd-4582-bce9-76f302afde09-c000.snappy.parquet\n",
      "-rw-r--r-- 1 andre andre 6418178 Mar  6 17:24 part-00002-9fcac57f-9abd-4582-bce9-76f302afde09-c000.snappy.parquet\n",
      "-rw-r--r-- 1 andre andre 6417268 Mar  6 17:24 part-00003-9fcac57f-9abd-4582-bce9-76f302afde09-c000.snappy.parquet\n",
      "-rw-r--r-- 1 andre andre 6421083 Mar  6 17:24 part-00004-9fcac57f-9abd-4582-bce9-76f302afde09-c000.snappy.parquet\n",
      "-rw-r--r-- 1 andre andre 6438857 Mar  6 17:24 part-00005-9fcac57f-9abd-4582-bce9-76f302afde09-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "# check files sizes\n",
    "! ls -l data/homework5/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d2e89-29ac-45df-bbd1-a24190074390",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2 : The average size of the parquet\n",
    "6 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec8f7f-3b0b-4cc7-8c35-6daaed9e97c6",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a93702-8eef-429b-b286-1000a98f623b",
   "metadata": {},
   "source": [
    "## Question3: Count records on October 15th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f603f0dd-06a3-44e5-96c0-f2ed91d1b3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# register the table\n",
    "df.createOrReplaceTempView(\"fhv_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d0ccb2-0b31-4f74-a63c-dd829dd5a172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the date column to the spark dataframe\n",
    "df = df.withColumn('pickup_date',F.to_date(df.pickup_datetime))\n",
    "\n",
    "df.select('pickup_date').filter(df.pickup_date == '2019-10-15').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71837c-a7a3-4fd2-a8a1-32dea8e10641",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "703310d4-fda6-4b4e-8a72-53a0aa956026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Calculate the duration of each trip in seconds\n",
    "df = df.withColumn(\"trip_duration_seconds\", df.dropoff_datetime-df.pickup_datetime)\n",
    "\n",
    "# Convert the duration from seconds to hours\n",
    "df = df.withColumn(\"trip_duration_hours\", df.trip_duration_seconds / 3600)\n",
    "\n",
    "df_result=spark.sql(\n",
    "    '''\n",
    "\n",
    "        SELECT MAX(trip_duration_hours) AS longest_trip_hours\n",
    "        FROM (\n",
    "            SELECT TIMESTAMPDIFF(SECOND, pickup_datetime, dropoff_datetime) / 3600.0 AS trip_duration_hours\n",
    "            FROM fhv_data\n",
    "        ) AS durations;\n",
    "        \n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8b1dd-e931-4748-b0cf-65f9ca7c0623",
   "metadata": {},
   "source": [
    "## Question 4: The Longest trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddd7c588-f92e-4908-b973-8e62124fbe12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|longest_trip_hours|\n",
      "+------------------+\n",
      "|     631152.500000|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83296a-bd30-4903-994c-e9fb6c4722a4",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c23fcc1-966d-4147-8aad-06f5bc7aa0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-06 17:56:23--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T175623Z&X-Amz-Expires=300&X-Amz-Signature=cd4e4b3533a01371c5c8d40c54046c5ab083127e804ff7dee7aedeafc039c2f4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-06 17:56:23--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T175623Z&X-Amz-Expires=300&X-Amz-Signature=cd4e4b3533a01371c5c8d40c54046c5ab083127e804ff7dee7aedeafc039c2f4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-03-06 17:56:24 (22.3 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download zone lookup csv \n",
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "438a4841-73bb-4fde-a123-f36e51d38404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read into dataframe\n",
    "zone_lookup = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')\n",
    "\n",
    "zone_lookup.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ad540c-ffeb-4fc7-8877-ed49c0378c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temp tables\n",
    "df.registerTempTable('trips_data')\n",
    "zone_lookup.registerTempTable('zone_lookup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14489506-c836-42c2-887c-ac6a9322c865",
   "metadata": {},
   "source": [
    "## Question 6 : Least frequent pickup location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8132a819-a21b-4536-86d8-c99cd3659536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|count(1)|                Zone|\n",
      "+--------+--------------------+\n",
      "|       1|         Jamaica Bay|\n",
      "|       2|Governor's Island...|\n",
      "|       5| Green-Wood Cemetery|\n",
      "|       8|       Broad Channel|\n",
      "|      14|     Highbridge Park|\n",
      "|      15|        Battery Park|\n",
      "|      23|Saint Michaels Ce...|\n",
      "|      25|Breezy Point/Fort...|\n",
      "|      26|Marine Park/Floyd...|\n",
      "|      29|        Astoria Park|\n",
      "|      39|    Inwood Hill Park|\n",
      "|      47|       Willets Point|\n",
      "|      53|Forest Park/Highl...|\n",
      "|      57|  Brooklyn Navy Yard|\n",
      "|      62|        Crotona Park|\n",
      "|      77|        Country Club|\n",
      "|      89|     Freshkills Park|\n",
      "|      98|       Prospect Park|\n",
      "|     105|     Columbia Street|\n",
      "|     110|  South Williamsburg|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Using the zone lookup data and the FHV October 2019 data, \n",
    "# what is the name of the LEAST frequent pickup location Zone?\n",
    "\n",
    "# column from trips_data : PUlocationID\n",
    "# column from zone_lookup : LocationID\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    count(1),\n",
    "    zone_lookup.Zone \n",
    "FROM \n",
    "    trips_data\n",
    "LEFT JOIN \n",
    "    zone_lookup\n",
    "ON\n",
    "    trips_data.PUlocationID = zone_lookup.LocationID \n",
    "GROUP BY \n",
    "    zone_lookup.Zone\n",
    "ORDER BY \n",
    "    count(1) ASC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b60cb-9a35-4d8e-a4e9-8b35551f11d0",
   "metadata": {},
   "source": [
    "## ======================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
